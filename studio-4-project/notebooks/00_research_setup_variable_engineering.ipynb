{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studio 4 Notebook 00: Research Setup & Variable Engineering\n",
    "\n",
    "**Research Question**: To what extent do pre-existing household wealth and demographic characteristics moderate the predictive relationship between higher education attainment and long-term financial stability for households within the same income quintile?\n",
    "\n",
    "**Sections**:\n",
    "1. Environment Setup and Data Loading\n",
    "2. Research Variable Definition and Creation\n",
    "3. Target Variables Engineering\n",
    "4. Predictor Variables Preparation\n",
    "5. Interaction Terms Creation\n",
    "6. Financial Stability Index Development\n",
    "7. Data Validation and Quality Checks\n",
    "\n",
    "**Author**: Studio 4 Research Team\n",
    "**Date**: 2026-02-10\n",
    "**Version**: 1.0\n",
    "\n",
    "**Dependencies**: Requires MVP Notebooks 00-02 completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Import statistical libraries\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Import progress tracking\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set up environment\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "print(\" Studio 4 environment setup complete!\")\n",
    "print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Define project paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "PROCESSED_DIR = OUTPUT_DIR / \"processed_data\"\n",
    "STUDIO4_DIR = Path.cwd()\n",
    "STUDIO4_OUTPUT = STUDIO4_DIR / \"output\"\n",
    "\n",
    "# Create Studio 4 output directories\n",
    "STUDIO4_OUTPUT.mkdir(exist_ok=True)\n",
    "(STUDIO4_OUTPUT / \"figures\").mkdir(exist_ok=True)\n",
    "(STUDIO4_OUTPUT / \"tables\").mkdir(exist_ok=True)\n",
    "(STUDIO4_OUTPUT / \"reports\").mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Studio 4 directories configured\")\n",
    "print(f\"   Project root: {PROJECT_ROOT}\")\n",
    "print(f\"   Studio 4 output: {STUDIO4_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Studio 4 Ready Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Studio 4 ready dataset from MVP notebooks\n",
    "studio4_data_path = PROCESSED_DIR / \"scf2022_studio4_ready.csv\"\n",
    "\n",
    "if studio4_data_path.exists():\n",
    "    print(\" Loading Studio 4 ready dataset from MVP notebooks...\")\n",
    "    df = pd.read_csv(studio4_data_path)\n",
    "    print(f\" Studio 4 data loaded successfully!\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "    print(f\"   Columns: {list(df.columns)}\")\n",
    "else:\n",
    "    # Fallback to analysis-ready dataset\n",
    "    analysis_data_path = PROCESSED_DIR / \"scf2022_analysis_ready.csv\"\n",
    "    if analysis_data_path.exists():\n",
    "        print(\" Studio 4 specific dataset not found, loading analysis dataset...\")\n",
    "        df = pd.read_csv(analysis_data_path)\n",
    "        print(f\" Analysis data loaded: {df.shape}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No suitable dataset found. Please run MVP notebooks first.\")\n",
    "\n",
    "# Load variable lists for reference\n",
    "variable_lists_path = PROCESSED_DIR / \"variable_lists.json\"\n",
    "if variable_lists_path.exists():\n",
    "    with open(variable_lists_path, 'r') as f:\n",
    "        variable_lists = json.load(f)\n",
    "    print(f\" Variable lists loaded for reference\")\n",
    "\n",
    "print(f\"\\n Studio 4 data ready for research!\")\n",
    "print(f\"   Households: {df.shape[0]:,}\")\n",
    "print(f\"   Variables: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Initialize Weighted Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import weighted analysis tools from MVP\n",
    "sys.path.append('../src')\n",
    "try:\n",
    "    from utils.weighted_analysis import WeightedSurveyAnalyzer\n",
    "    print(\" Weighted survey analyzer imported\")\n",
    "except ImportError:\n",
    "    print(\" Weighted analyzer not available, using basic pandas methods\")\n",
    "    WeightedSurveyAnalyzer = None\n",
    "\n",
    "# Initialize weighted analyzer if available\n",
    "if 'WGT' in df.columns and WeightedSurveyAnalyzer is not None:\n",
    "    weighted_analyzer = WeightedSurveyAnalyzer(df, 'WGT')\n",
    "    print(\" Weighted survey analyzer initialized\")\n",
    "    print(f\"   Survey weights: {df['WGT'].notna().sum():,} non-missing\")\n",
    "    print(f\"   Total weight: {df['WGT'].sum():,.0f}\")\n",
    "else:\n",
    "    print(\" Survey weights not available - using unweighted analysis\")\n",
    "    weighted_analyzer = None\n",
    "\n",
    "# Verify key variables for Studio 4 research\n",
    "studio4_critical_vars = [\n",
    "    'INCOME_QUINTILE', 'WEALTH_QUINTILE', 'EDCL', 'RACECL4', \n",
    "    'NETWORTH', 'INCOME', 'WGT', 'AGE', 'MARRIED', 'KIDS', 'HHSEX'\n",
    "]\n",
    "\n",
    "available_vars = [var for var in studio4_critical_vars if var in df.columns]\n",
    "missing_vars = [var for var in studio4_critical_vars if var not in df.columns]\n",
    "\n",
    "print(f\"\\nüîë Studio 4 Critical Variables Status:\")\n",
    "print(f\"   Available: {len(available_vars)}/{len(studio4_critical_vars)}\")\n",
    "print(f\"   Available vars: {available_vars}\")\n",
    "if missing_vars:\n",
    "    print(f\"   Missing vars: {missing_vars}\")\n",
    "else:\n",
    "    print(f\"    All critical variables present!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Research Variable Definition and Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define Research Variable Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comprehensive research variable framework\n",
    "print(\" Defining Studio 4 research variable framework...\")\n",
    "\n",
    "research_variables = {\n",
    "    \n",
    "    # Target Variables (Financial Stability Outcomes)\n",
    "    'target_variables': {\n",
    "        'payment_stress': {\n",
    "            'LATE': 'Household had any late debt payments in last year',\n",
    "            'LATE60': 'Household had any debt payments more than 60 days past due',\n",
    "            'PIR40_STRESS': 'Household has payment-to-income ratio higher than 40%'\n",
    "        },\n",
    "        'debt_burden': {\n",
    "            'DEBT2INC': 'Ratio of total debt to total income',\n",
    "            'PIRTOTAL': 'Ratio of monthly debt payments to monthly income',\n",
    "            'LEVERAGE_RATIO': 'Ratio of total debt to total assets'\n",
    "        },\n",
    "        'financial_position': {\n",
    "            'NETWORTH': 'Total net worth of household, 2022 dollars',\n",
    "            'LIQUID_ASSETS_IND': 'Has liquid assets above median',\n",
    "            'SAVING_BEHAVIOR': 'Positive saving behavior indicator'\n",
    "        },\n",
    "        'financial_knowledge': {\n",
    "            'KNOWL': 'Knowledge of personal finances score'\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Main Predictor Variables\n",
    "    'predictor_variables': {\n",
    "        'education': {\n",
    "            'EDCL': 'Education class (1-5)',\n",
    "            'EDUC': 'Education years',\n",
    "            'EDUCATION_LABEL': 'Education category label'\n",
    "        },\n",
    "        'income_controls': {\n",
    "            'INCOME': 'Total family income',\n",
    "            'INCOME_QUINTILE': 'Income quintile (1-5)',\n",
    "            'INCOME_CAT': 'Income category'\n",
    "        },\n",
    "        'demographics': {\n",
    "            'RACECL4': 'Race/ethnicity (4-category)',\n",
    "            'HHSEX': 'Head of household sex (1=Male, 2=Female)',\n",
    "            'AGE': 'Age of head of household',\n",
    "            'AGECL': 'Age category',\n",
    "            'MARRIED': 'Marital status (1=Married, 2=Unmarried)',\n",
    "            'KIDS': 'Number of children'\n",
    "        },\n",
    "        'wealth_background': {\n",
    "            'NETWORTH': 'Household net worth',\n",
    "            'WEALTH_QUINTILE': 'Wealth quintile (1-5)',\n",
    "            'NWPCTLECAT': 'Net worth percentile category'\n",
    "        },\n",
    "        'debt_structure': {\n",
    "            'HEDN_INST': 'Home equity installment debt',\n",
    "            'EDN_INST': 'Education installment debt',\n",
    "            'DEBT': 'Total debt',\n",
    "            'CCBAL': 'Credit card balance',\n",
    "            'RESDBT': 'Residence debt'\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Interaction Variables (Moderation Effects)\n",
    "    'interaction_variables': {\n",
    "        'education_x_wealth': {\n",
    "            'EDCL_WEALTH_INTERACTION': 'Education √ó Wealth quintile interaction'\n",
    "        },\n",
    "        'education_x_race': {\n",
    "            'EDUC_RACE_INTERACTION': 'Education √ó Race interaction'\n",
    "        },\n",
    "        'education_x_income': {\n",
    "            'EDCL_INCOME_INTERACTION': 'Education √ó Income level interaction'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\n Research Variable Framework Defined:\")\n",
    "for category, variables in research_variables.items():\n",
    "    print(f\"\\n   {category.upper()}:\")\n",
    "    for subcategory, var_dict in variables.items():\n",
    "        print(f\"      {subcategory}: {len(var_dict)} variables\")\n",
    "        for var, desc in var_dict.items():\n",
    "            if var in df.columns:\n",
    "                print(f\"          {var}: {desc}\")\n",
    "            else:\n",
    "                print(f\"         ‚ùå {var}: {desc} (MISSING)\")\n",
    "\n",
    "print(f\"\\n Framework ready for variable engineering!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target Variables Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create Payment Stress Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create payment stress target variables\n",
    "print(\" Creating payment stress variables...\")\n",
    "\n",
    "payment_stress_vars = []\n",
    "\n",
    "# Late payment indicators\n",
    "if 'LATE' in df.columns:\n",
    "    # Binary indicator for any late payments\n",
    "    df['LATE_PAYMENT_STRESS'] = (df['LATE'] == 1).astype(int)\n",
    "    payment_stress_vars.append('LATE_PAYMENT_STRESS')\n",
    "    print(f\"    Created LATE_PAYMENT_STRESS: {(df['LATE_PAYMENT_STRESS'].sum() / len(df) * 100):.1f}% households with late payments\")\n",
    "\n",
    "if 'LATE60' in df.columns:\n",
    "    # Binary indicator for severely late payments (60+ days)\n",
    "    df['SEVERE_LATE_STRESS'] = (df['LATE60'] == 1).astype(int)\n",
    "    payment_stress_vars.append('SEVERE_LATE_STRESS')\n",
    "    print(f\"    Created SEVERE_LATE_STRESS: {(df['SEVERE_LATE_STRESS'].sum() / len(df) * 100):.1f}% households with severe late payments\")\n",
    "\n",
    "# Payment-to-income ratio stress\n",
    "if 'PIRTOTAL' in df.columns:\n",
    "    # High payment burden indicator (>40% of income to debt payments)\n",
    "    df['HIGH_PAYMENT_BURDEN'] = (df['PIRTOTAL'] > 0.40).astype(int)\n",
    "    payment_stress_vars.append('HIGH_PAYMENT_BURDEN')\n",
    "    print(f\"    Created HIGH_PAYMENT_BURDEN: {(df['HIGH_PAYMENT_BURDEN'].sum() / len(df) * 100):.1f}% households with >40% payment burden\")\n",
    "    \n",
    "    # Continuous payment stress measure\n",
    "    df['PAYMENT_STRESS_CONTINUOUS'] = df['PIRTOTAL']\n",
    "    payment_stress_vars.append('PAYMENT_STRESS_CONTINUOUS')\n",
    "    print(f\"    Created PAYMENT_STRESS_CONTINUOUS: Mean {df['PAYMENT_STRESS_CONTINUOUS'].mean():.3f}\")\n",
    "\n",
    "# Composite payment stress index\n",
    "available_stress_indicators = [var for var in ['LATE_PAYMENT_STRESS', 'SEVERE_LATE_STRESS', 'HIGH_PAYMENT_BURDEN'] if var in df.columns]\n",
    "if len(available_stress_indicators) >= 2:\n",
    "    df['COMPOSITE_PAYMENT_STRESS'] = df[available_stress_indicators].sum(axis=1)\n",
    "    payment_stress_vars.append('COMPOSITE_PAYMENT_STRESS')\n",
    "    print(f\"    Created COMPOSITE_PAYMENT_STRESS: Range {df['COMPOSITE_PAYMENT_STRESS'].min()}-{df['COMPOSITE_PAYMENT_STRESS'].max()}\")\n",
    "\n",
    "print(f\"\\n Payment Stress Variables Created: {len(payment_stress_vars)}\")\n",
    "print(f\"   Variables: {payment_stress_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create Debt Burden Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create debt burden target variables\n",
    "print(\" Creating debt burden variables...\")\n",
    "\n",
    "debt_burden_vars = []\n",
    "\n",
    "# Debt-to-income ratio\n",
    "if 'DEBT2INC' in df.columns:\n",
    "    # High debt burden indicator (>0.5 debt-to-income ratio)\n",
    "    df['HIGH_DEBT_BURDEN'] = (df['DEBT2INC'] > 0.5).astype(int)\n",
    "    debt_burden_vars.append('HIGH_DEBT_BURDEN')\n",
    "    print(f\"    Created HIGH_DEBT_BURDEN: {(df['HIGH_DEBT_BURDEN'].sum() / len(df) * 100):.1f}% households with >50% debt burden\")\n",
    "    \n",
    "    # Continuous debt burden measure\n",
    "    df['DEBT_BURDEN_CONTINUOUS'] = df['DEBT2INC']\n",
    "    debt_burden_vars.append('DEBT_BURDEN_CONTINUOUS')\n",
    "    print(f\"    Created DEBT_BURDEN_CONTINUOUS: Mean {df['DEBT_BURDEN_CONTINUOUS'].mean():.3f}\")\n",
    "\n",
    "# Leverage ratio (debt-to-assets)\n",
    "if 'LEVERAGE_RATIO' in df.columns:\n",
    "    # High leverage indicator (>0.8 leverage ratio)\n",
    "    df['HIGH_LEVERAGE'] = (df['LEVERAGE_RATIO'] > 0.8).astype(int)\n",
    "    debt_burden_vars.append('HIGH_LEVERAGE')\n",
    "    print(f\"    Created HIGH_LEVERAGE: {(df['HIGH_LEVERAGE'].sum() / len(df) * 100):.1f}% households with >80% leverage\")\n",
    "    \n",
    "    # Continuous leverage measure\n",
    "    df['LEVERAGE_CONTINUOUS'] = df['LEVERAGE_RATIO']\n",
    "    debt_burden_vars.append('LEVERAGE_CONTINUOUS')\n",
    "    print(f\"    Created LEVERAGE_CONTINUOUS: Mean {df['LEVERAGE_CONTINUOUS'].mean():.3f}\")\n",
    "\n",
    "# Composite debt burden index\n",
    "available_debt_indicators = [var for var in ['DEBT_BURDEN_CONTINUOUS', 'LEVERAGE_CONTINUOUS', 'PAYMENT_STRESS_CONTINUOUS'] if var in df.columns]\n",
    "if len(available_debt_indicators) >= 2:\n",
    "    # Standardize and combine debt burden measures\n",
    "    debt_scores = []\n",
    "    for var in available_debt_indicators:\n",
    "        # Standardize (z-score)\n",
    "        z_score = (df[var] - df[var].mean()) / df[var].std()\n",
    "        debt_scores.append(z_score)\n",
    "    \n",
    "    if debt_scores:\n",
    "        df['COMPOSITE_DEBT_BURDEN'] = np.mean(debt_scores, axis=0)\n",
    "        debt_burden_vars.append('COMPOSITE_DEBT_BURDEN')\n",
    "        print(f\"    Created COMPOSITE_DEBT_BURDEN: Standardized index\")\n",
    "\n",
    "print(f\"\\n Debt Burden Variables Created: {len(debt_burden_vars)}\")\n",
    "print(f\"   Variables: {debt_burden_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create Financial Position Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create financial position target variables\n",
    "print(\" Creating financial position variables...\")\n",
    "\n",
    "financial_position_vars = []\n",
    "\n",
    "# Net worth categories\n",
    "if 'NETWORTH' in df.columns:\n",
    "    # Low net worth indicator (bottom quartile)\n",
    "    networth_q25 = df['NETWORTH'].quantile(0.25)\n",
    "    df['LOW_NETWORTH'] = (df['NETWORTH'] <= networth_q25).astype(int)\n",
    "    financial_position_vars.append('LOW_NETWORTH')\n",
    "    print(f\"    Created LOW_NETWORTH: {(df['LOW_NETWORTH'].sum() / len(df) * 100):.1f}% households in bottom quartile\")\n",
    "    \n",
    "    # High net worth indicator (top quartile)\n",
    "    networth_q75 = df['NETWORTH'].quantile(0.75)\n",
    "    df['HIGH_NETWORTH'] = (df['NETWORTH'] >= networth_q75).astype(int)\n",
    "    financial_position_vars.append('HIGH_NETWORTH')\n",
    "    print(f\"    Created HIGH_NETWORTH: {(df['HIGH_NETWORTH'].sum() / len(df) * 100):.1f}% households in top quartile\")\n",
    "    \n",
    "    # Continuous net worth (log transformed for normalization)\n",
    "    df['LOG_NETWORTH'] = np.log1p(np.maximum(df['NETWORTH'], 0))\n",
    "    financial_position_vars.append('LOG_NETWORTH')\n",
    "    print(f\"    Created LOG_NETWORTH: Mean {df['LOG_NETWORTH'].mean():.3f}\")\n",
    "\n",
    "# Liquid assets indicator\n",
    "if 'LIQUID_ASSETS_IND' in df.columns:\n",
    "    financial_position_vars.append('LIQUID_ASSETS_IND')\n",
    "    print(f\"    LIQUID_ASSETS_IND available: {(df['LIQUID_ASSETS_IND'].sum() / len(df) * 100):.1f}% have high liquid assets\")\n",
    "\n",
    "# Saving behavior indicator\n",
    "if 'SAVING_BEHAVIOR' in df.columns:\n",
    "    financial_position_vars.append('SAVING_BEHAVIOR')\n",
    "    print(f\"    SAVING_BEHAVIOR available: {(df['SAVING_BEHAVIOR'].sum() / len(df) * 100):.1f}% have positive saving behavior\")\n",
    "\n",
    "# Financial resilience index\n",
    "resilience_components = []\n",
    "if 'LOG_NETWORTH' in df.columns:\n",
    "    resilience_components.append('LOG_NETWORTH')\n",
    "if 'LIQUID_ASSETS_IND' in df.columns:\n",
    "    resilience_components.append('LIQUID_ASSETS_IND')\n",
    "if 'SAVING_BEHAVIOR' in df.columns:\n",
    "    resilience_components.append('SAVING_BEHAVIOR')\n",
    "\n",
    "if len(resilience_components) >= 2:\n",
    "    # Standardize and combine resilience components\n",
    "    resilience_scores = []\n",
    "    for var in resilience_components:\n",
    "        if var == 'LOG_NETWORTH':\n",
    "            # Already log-transformed, just standardize\n",
    "            z_score = (df[var] - df[var].mean()) / df[var].std()\n",
    "        else:\n",
    "            # Binary indicator, convert to z-score\n",
    "            z_score = (df[var] - df[var].mean()) / df[var].std()\n",
    "        resilience_scores.append(z_score)\n",
    "    \n",
    "    if resilience_scores:\n",
    "        df['FINANCIAL_RESILIENCE_INDEX'] = np.mean(resilience_scores, axis=0)\n",
    "        financial_position_vars.append('FINANCIAL_RESILIENCE_INDEX')\n",
    "        print(f\"    Created FINANCIAL_RESILIENCE_INDEX: Standardized index\")\n",
    "\n",
    "print(f\"\\n Financial Position Variables Created: {len(financial_position_vars)}\")\n",
    "print(f\"   Variables: {financial_position_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Create Financial Knowledge Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create financial knowledge target variables\n",
    "print(\"üß† Creating financial knowledge variables...\")\n",
    "\n",
    "financial_knowledge_vars = []\n",
    "\n",
    "# Financial knowledge score\n",
    "if 'KNOWL' in df.columns:\n",
    "    # High financial knowledge indicator (top quartile)\n",
    "    knowl_q75 = df['KNOWL'].quantile(0.75)\n",
    "    df['HIGH_FINANCIAL_KNOWLEDGE'] = (df['KNOWL'] >= knowl_q75).astype(int)\n",
    "    financial_knowledge_vars.append('HIGH_FINANCIAL_KNOWLEDGE')\n",
    "    print(f\"    Created HIGH_FINANCIAL_KNOWLEDGE: {(df['HIGH_FINANCIAL_KNOWLEDGE'].sum() / len(df) * 100):.1f}% have high knowledge\")\n",
    "    \n",
    "    # Low financial knowledge indicator (bottom quartile)\n",
    "    knowl_q25 = df['KNOWL'].quantile(0.25)\n",
    "    df['LOW_FINANCIAL_KNOWLEDGE'] = (df['KNOWL'] <= knowl_q25).astype(int)\n",
    "    financial_knowledge_vars.append('LOW_FINANCIAL_KNOWLEDGE')\n",
    "    print(f\"    Created LOW_FINANCIAL_KNOWLEDGE: {(df['LOW_FINANCIAL_KNOWLEDGE'].sum() / len(df) * 100):.1f}% have low knowledge\")\n",
    "    \n",
    "    # Continuous financial knowledge measure\n",
    "    df['FINANCIAL_KNOWLEDGE_CONTINUOUS'] = df['KNOWL']\n",
    "    financial_knowledge_vars.append('FINANCIAL_KNOWLEDGE_CONTINUOUS')\n",
    "    print(f\"    Created FINANCIAL_KNOWLEDGE_CONTINUOUS: Mean {df['FINANCIAL_KNOWLEDGE_CONTINUOUS'].mean():.2f}\")\n",
    "\n",
    "print(f\"\\n Financial Knowledge Variables Created: {len(financial_knowledge_vars)}\")\n",
    "print(f\"   Variables: {financial_knowledge_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictor Variables Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Prepare Education Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare education predictor variables\n",
    "print(\" Preparing education predictor variables...\")\n",
    "\n",
    "education_vars = []\n",
    "\n",
    "# Education class (main predictor)\n",
    "if 'EDCL' in df.columns:\n",
    "    # Ensure EDCL is properly coded as categorical\n",
    "    df['EDCL'] = df['EDCL'].astype('category')\n",
    "    education_vars.append('EDCL')\n",
    "    print(f\"    EDCL prepared: {df['EDCL'].nunique()} categories\")\n",
    "    print(f\"      Distribution: {dict(df['EDCL'].value_counts().sort_index())}\")\n",
    "\n",
    "# Education years (if available)\n",
    "if 'EDUC' in df.columns:\n",
    "    education_vars.append('EDUC')\n",
    "    print(f\"    EDUC prepared: Mean {df['EDUC'].mean():.1f} years\")\n",
    "\n",
    "# Education dummies for regression\n",
    "if 'EDCL' in df.columns:\n",
    "    # Create dummy variables for education (using lowest category as reference)\n",
    "    edu_dummies = pd.get_dummies(df['EDCL'], prefix='EDU', drop_first=True)\n",
    "    df = pd.concat([df, edu_dummies], axis=1)\n",
    "    education_vars.extend(edu_dummies.columns.tolist())\n",
    "    print(f\"    Created {len(edu_dummies)} education dummy variables\")\n",
    "    print(f\"      Dummy variables: {list(edu_dummies.columns)}\")\n",
    "\n",
    "# Education labels for visualization\n",
    "if 'EDUCATION_LABEL' in df.columns:\n",
    "    education_vars.append('EDUCATION_LABEL')\n",
    "    print(f\"    EDUCATION_LABEL available for visualization\")\n",
    "\n",
    "print(f\"\\n Education Predictor Variables Prepared: {len(education_vars)}\")\n",
    "print(f\"   Variables: {education_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Prepare Demographic Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare demographic predictor variables\n",
    "print(\" Preparing demographic predictor variables...\")\n",
    "\n",
    "demographic_vars = []\n",
    "\n",
    "# Race/ethnicity\n",
    "if 'RACECL4' in df.columns:\n",
    "    df['RACECL4'] = df['RACECL4'].astype('category')\n",
    "    demographic_vars.append('RACECL4')\n",
    "    print(f\"    RACECL4 prepared: {df['RACECL4'].nunique()} categories\")\n",
    "    \n",
    "    # Create race dummies (using reference category)\n",
    "    race_dummies = pd.get_dummies(df['RACECL4'], prefix='RACE', drop_first=True)\n",
    "    df = pd.concat([df, race_dummies], axis=1)\n",
    "    demographic_vars.extend(race_dummies.columns.tolist())\n",
    "    print(f\"      Created {len(race_dummies)} race dummy variables\")\n",
    "\n",
    "# Gender\n",
    "if 'HHSEX' in df.columns:\n",
    "    df['HHSEX'] = df['HHSEX'].astype('category')\n",
    "    demographic_vars.append('HHSEX')\n",
    "    print(f\"    HHSEX prepared: {dict(df['HHSEX'].value_counts())}\")\n",
    "    \n",
    "    # Create female dummy (male as reference)\n",
    "    df['FEMALE'] = (df['HHSEX'] == 2).astype(int)\n",
    "    demographic_vars.append('FEMALE')\n",
    "    print(f\"      Created FEMALE dummy: {(df['FEMALE'].sum() / len(df) * 100):.1f}% female\")\n",
    "\n",
    "# Age\n",
    "if 'AGE' in df.columns:\n",
    "    demographic_vars.append('AGE')\n",
    "    print(f\"    AGE prepared: Mean {df['AGE'].mean():.1f} years\")\n",
    "    \n",
    "    # Age squared for non-linear effects\n",
    "    df['AGE_SQUARED'] = df['AGE'] ** 2\n",
    "    demographic_vars.append('AGE_SQUARED')\n",
    "    print(f\"      Created AGE_SQUARED for non-linear effects\")\n",
    "\n",
    "# Marital status\n",
    "if 'MARRIED' in df.columns:\n",
    "    df['MARRIED'] = df['MARRIED'].astype('category')\n",
    "    demographic_vars.append('MARRIED')\n",
    "    print(f\"    MARRIED prepared: {dict(df['MARRIED'].value_counts())}\")\n",
    "    \n",
    "    # Create married dummy (unmarried as reference)\n",
    "    df['MARRIED_DUMMY'] = (df['MARRIED'] == 1).astype(int)\n",
    "    demographic_vars.append('MARRIED_DUMMY')\n",
    "    print(f\"      Created MARRIED_DUMMY: {(df['MARRIED_DUMMY'].sum() / len(df) * 100):.1f}% married\")\n",
    "\n",
    "# Number of children\n",
    "if 'KIDS' in df.columns:\n",
    "    demographic_vars.append('KIDS')\n",
    "    print(f\"    KIDS prepared: Mean {df['KIDS'].mean():.1f} children\")\n",
    "    \n",
    "    # Has children dummy\n",
    "    df['HAS_CHILDREN'] = (df['KIDS'] > 0).astype(int)\n",
    "    demographic_vars.append('HAS_CHILDREN')\n",
    "    print(f\"      Created HAS_CHILDREN: {(df['HAS_CHILDREN'].sum() / len(df) * 100):.1f}% have children\")\n",
    "\n",
    "print(f\"\\n Demographic Predictor Variables Prepared: {len(demographic_vars)}\")\n",
    "print(f\"   Variables: {demographic_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Prepare Wealth Background Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare wealth background predictor variables\n",
    "print(\"üíé Preparing wealth background predictor variables...\")\n",
    "\n",
    "wealth_background_vars = []\n",
    "\n",
    "# Wealth quintile (key moderator)\n",
    "if 'WEALTH_QUINTILE' in df.columns:\n",
    "    df['WEALTH_QUINTILE'] = df['WEALTH_QUINTILE'].astype('category')\n",
    "    wealth_background_vars.append('WEALTH_QUINTILE')\n",
    "    print(f\"    WEALTH_QUINTILE prepared: {df['WEALTH_QUINTILE'].nunique()} categories\")\n",
    "    print(f\"      Distribution: {dict(df['WEALTH_QUINTILE'].value_counts().sort_index())}\")\n",
    "    \n",
    "    # Create wealth dummies (using bottom quintile as reference)\n",
    "    wealth_dummies = pd.get_dummies(df['WEALTH_QUINTILE'], prefix='WEALTH_Q', drop_first=True)\n",
    "    df = pd.concat([df, wealth_dummies], axis=1)\n",
    "    wealth_background_vars.extend(wealth_dummies.columns.tolist())\n",
    "    print(f\"      Created {len(wealth_dummies)} wealth quintile dummy variables\")\n",
    "\n",
    "# Net worth (continuous wealth measure)\n",
    "if 'NETWORTH' in df.columns:\n",
    "    wealth_background_vars.append('NETWORTH')\n",
    "    print(f\"    NETWORTH prepared: Mean ${df['NETWORTH'].mean():,.0f}\")\n",
    "    \n",
    "    # Log net worth for normalization\n",
    "    if 'LOG_NETWORTH' not in df.columns:\n",
    "        df['LOG_NETWORTH'] = np.log1p(np.maximum(df['NETWORTH'], 0))\n",
    "    wealth_background_vars.append('LOG_NETWORTH')\n",
    "    print(f\"      Created LOG_NETWORTH: Mean {df['LOG_NETWORTH'].mean():.3f}\")\n",
    "\n",
    "# Net worth percentile category (if available)\n",
    "if 'NWPCTLECAT' in df.columns:\n",
    "    df['NWPCTLECAT'] = df['NWPCTLECAT'].astype('category')\n",
    "    wealth_background_vars.append('NWPCTLECAT')\n",
    "    print(f\"    NWPCTLECAT prepared: {df['NWPCTLECAT'].nunique()} categories\")\n",
    "\n",
    "# Asset ownership indicators (wealth proxies)\n",
    "asset_indicators = {\n",
    "    'HOMEOWNER': 'HOUSES',\n",
    "    'STOCKOWNER': 'STOCKS',\n",
    "    'RETIREMENT_ACCOUNT': 'RETQLIQ'\n",
    "}\n",
    "\n",
    "for indicator, asset_var in asset_indicators.items():\n",
    "    if asset_var in df.columns:\n",
    "        # Create binary indicator for asset ownership\n",
    "        df[indicator] = (df[asset_var] > 0).astype(int)\n",
    "        wealth_background_vars.append(indicator)\n",
    "        print(f\"    Created {indicator}: {(df[indicator].sum() / len(df) * 100):.1f}% own {asset_var.lower()}\")\n",
    "\n",
    "print(f\"\\n Wealth Background Predictor Variables Prepared: {len(wealth_background_vars)}\")\n",
    "print(f\"   Variables: {wealth_background_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Prepare Income Control Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare income control variables\n",
    "print(\" Preparing income control variables...\")\n",
    "\n",
    "income_control_vars = []\n",
    "\n",
    "# Income quintile (key for within-quintile analysis)\n",
    "if 'INCOME_QUINTILE' in df.columns:\n",
    "    df['INCOME_QUINTILE'] = df['INCOME_QUINTILE'].astype('category')\n",
    "    income_control_vars.append('INCOME_QUINTILE')\n",
    "    print(f\"    INCOME_QUINTILE prepared: {df['INCOME_QUINTILE'].nunique()} categories\")\n",
    "    print(f\"      Distribution: {dict(df['INCOME_QUINTILE'].value_counts().sort_index())}\")\n",
    "\n",
    "# Total income (continuous control)\n",
    "if 'INCOME' in df.columns:\n",
    "    income_control_vars.append('INCOME')\n",
    "    print(f\"    INCOME prepared: Mean ${df['INCOME'].mean():,.0f}\")\n",
    "    \n",
    "    # Log income for normalization\n",
    "    df['LOG_INCOME'] = np.log1p(np.maximum(df['INCOME'], 0))\n",
    "    income_control_vars.append('LOG_INCOME')\n",
    "    print(f\"      Created LOG_INCOME: Mean {df['LOG_INCOME'].mean():.3f}\")\n",
    "\n",
    "# Income category (if available)\n",
    "if 'INCOME_CAT' in df.columns:\n",
    "    df['INCOME_CAT'] = df['INCOME_CAT'].astype('category')\n",
    "    income_control_vars.append('INCOME_CAT')\n",
    "    print(f\"    INCOME_CAT prepared: {df['INCOME_CAT'].nunique()} categories\")\n",
    "\n",
    "# Income source composition (if available)\n",
    "income_ratios = ['WAGE_RATIO', 'BUSINESS_RATIO', 'INVESTMENT_RATIO', 'RETIREMENT_INCOME_RATIO']\n",
    "for ratio_var in income_ratios:\n",
    "    if ratio_var in df.columns:\n",
    "        income_control_vars.append(ratio_var)\n",
    "        print(f\"    {ratio_var} prepared: Mean {df[ratio_var].mean():.3f}\")\n",
    "\n",
    "print(f\"\\n Income Control Variables Prepared: {len(income_control_vars)}\")\n",
    "print(f\"   Variables: {income_control_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interaction Terms Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create Education √ó Wealth Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create education √ó wealth interaction terms\n",
    "print(\" Creating education √ó wealth interaction terms...\")\n",
    "\n",
    "interaction_vars = []\n",
    "\n",
    "if 'EDCL' in df.columns and 'WEALTH_QUINTILE' in df.columns:\n",
    "    # Create interaction variable\n",
    "    df['EDUC_WEALTH_INTERACTION'] = df['EDCL'].astype(str) + '_Q' + df['WEALTH_QUINTILE'].astype(str)\n",
    "    interaction_vars.append('EDUC_WEALTH_INTERACTION')\n",
    "    print(f\"    Created EDUC_WEALTH_INTERACTION: {df['EDUC_WEALTH_INTERACTION'].nunique()} unique combinations\")\n",
    "    \n",
    "    # Create interaction dummies for regression\n",
    "    educ_wealth_dummies = pd.get_dummies(df['EDUC_WEALTH_INTERACTION'], prefix='EDU_WEALTH', drop_first=True)\n",
    "    df = pd.concat([df, educ_wealth_dummies], axis=1)\n",
    "    interaction_vars.extend(educ_wealth_dummies.columns.tolist())\n",
    "    print(f\"      Created {len(educ_wealth_dummies)} education-wealth interaction dummies\")\n",
    "    \n",
    "    # Create continuous interaction term (education √ó log wealth)\n",
    "    if 'LOG_NETWORTH' in df.columns:\n",
    "        # Convert education to numeric for interaction\n",
    "        df['EDCL_NUMERIC'] = df['EDCL'].astype(int)\n",
    "        df['EDUC_LOG_WEALTH_INTERACTION'] = df['EDCL_NUMERIC'] * df['LOG_NETWORTH']\n",
    "        interaction_vars.append('EDUC_LOG_WEALTH_INTERACTION')\n",
    "        print(f\"      Created EDUC_LOG_WEALTH_INTERACTION: Continuous interaction term\")\n",
    "    \n",
    "    # Display interaction distribution\n",
    "    interaction_dist = df.groupby(['EDCL', 'WEALTH_QUINTILE']).size().unstack(fill_value=0)\n",
    "    print(f\"\\n    Education √ó Wealth Interaction Distribution:\")\n",
    "    display(interaction_dist)\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot create education √ó wealth interaction - missing EDCL or WEALTH_QUINTILE\")\n",
    "\n",
    "print(f\"\\n Education √ó Wealth Interaction Variables Created: {len(interaction_vars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create Education √ó Race Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create education √ó race interaction terms\n",
    "print(\" Creating education √ó race interaction terms...\")\n",
    "\n",
    "race_interaction_vars = []\n",
    "\n",
    "if 'EDCL' in df.columns and 'RACECL4' in df.columns:\n",
    "    # Create interaction variable\n",
    "    df['EDUC_RACE_INTERACTION'] = df['EDCL'].astype(str) + '_' + df['RACECL4'].astype(str)\n",
    "    race_interaction_vars.append('EDUC_RACE_INTERACTION')\n",
    "    print(f\"    Created EDUC_RACE_INTERACTION: {df['EDUC_RACE_INTERACTION'].nunique()} unique combinations\")\n",
    "    \n",
    "    # Create interaction dummies for regression\n",
    "    educ_race_dummies = pd.get_dummies(df['EDUC_RACE_INTERACTION'], prefix='EDU_RACE', drop_first=True)\n",
    "    df = pd.concat([df, educ_race_dummies], axis=1)\n",
    "    race_interaction_vars.extend(educ_race_dummies.columns.tolist())\n",
    "    print(f\"      Created {len(educ_race_dummies)} education-race interaction dummies\")\n",
    "    \n",
    "    # Create continuous interaction term (education √ó race dummies)\n",
    "    if 'RACECL4' in df.columns:\n",
    "        # Convert education to numeric\n",
    "        if 'EDCL_NUMERIC' not in df.columns:\n",
    "            df['EDCL_NUMERIC'] = df['EDCL'].astype(int)\n",
    "        \n",
    "        # Create race dummies for interaction\n",
    "        race_dummies = pd.get_dummies(df['RACECL4'], prefix='RACE', drop_first=True)\n",
    "        for race_dummy in race_dummies.columns:\n",
    "            interaction_term = df['EDCL_NUMERIC'] * race_dummies[race_dummy]\n",
    "            df[f'EDUC_{race_dummy}_INTERACTION'] = interaction_term\n",
    "            race_interaction_vars.append(f'EDUC_{race_dummy}_INTERACTION')\n",
    "        \n",
    "        print(f\"      Created {len(race_dummies)} continuous education-race interactions\")\n",
    "    \n",
    "    # Display interaction distribution\n",
    "    interaction_dist = df.groupby(['EDCL', 'RACECL4']).size().unstack(fill_value=0)\n",
    "    print(f\"\\n    Education √ó Race Interaction Distribution:\")\n",
    "    display(interaction_dist)\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot create education √ó race interaction - missing EDCL or RACECL4\")\n",
    "\n",
    "print(f\"\\n Education √ó Race Interaction Variables Created: {len(race_interaction_vars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Create Education √ó Income Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create education √ó income interaction terms\n",
    "print(\" Creating education √ó income interaction terms...\")\n",
    "\n",
    "income_interaction_vars = []\n",
    "\n",
    "if 'EDCL' in df.columns and 'INCOME' in df.columns:\n",
    "    # Create continuous interaction term (education √ó log income)\n",
    "    if 'LOG_INCOME' in df.columns:\n",
    "        # Convert education to numeric\n",
    "        if 'EDCL_NUMERIC' not in df.columns:\n",
    "            df['EDCL_NUMERIC'] = df['EDCL'].astype(int)\n",
    "        \n",
    "        df['EDUC_LOG_INCOME_INTERACTION'] = df['EDCL_NUMERIC'] * df['LOG_INCOME']\n",
    "        income_interaction_vars.append('EDUC_LOG_INCOME_INTERACTION')\n",
    "        print(f\"    Created EDUC_LOG_INCOME_INTERACTION: Continuous interaction term\")\n",
    "        print(f\"      Mean: {df['EDUC_LOG_INCOME_INTERACTION'].mean():.3f}\")\n",
    "    \n",
    "    # Create education √ó income quintile interaction\n",
    "    if 'INCOME_QUINTILE' in df.columns:\n",
    "        df['EDUC_INCOME_INTERACTION'] = df['EDCL'].astype(str) + '_IQ' + df['INCOME_QUINTILE'].astype(str)\n",
    "        income_interaction_vars.append('EDUC_INCOME_INTERACTION')\n",
    "        print(f\"    Created EDUC_INCOME_INTERACTION: {df['EDUC_INCOME_INTERACTION'].nunique()} unique combinations\")\n",
    "        \n",
    "        # Create interaction dummies for regression\n",
    "        educ_income_dummies = pd.get_dummies(df['EDUC_INCOME_INTERACTION'], prefix='EDU_INCOME', drop_first=True)\n",
    "        df = pd.concat([df, educ_income_dummies], axis=1)\n",
    "        income_interaction_vars.extend(educ_income_dummies.columns.tolist())\n",
    "        print(f\"      Created {len(educ_income_dummies)} education-income interaction dummies\")\n",
    "    \n",
    "    # Display interaction with income quintile distribution\n",
    "    if 'INCOME_QUINTILE' in df.columns:\n",
    "        interaction_dist = df.groupby(['EDCL', 'INCOME_QUINTILE']).size().unstack(fill_value=0)\n",
    "        print(f\"\\n    Education √ó Income Quintile Interaction Distribution:\")\n",
    "        display(interaction_dist)\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot create education √ó income interaction - missing EDCL or INCOME\")\n",
    "\n",
    "print(f\"\\n Education √ó Income Interaction Variables Created: {len(income_interaction_vars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Financial Stability Index Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Create Comprehensive Financial Stability Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive Financial Stability Index (FSI)\n",
    "print(\"üèóÔ∏è Creating comprehensive Financial Stability Index...\")\n",
    "\n",
    "fsi_components = {\n",
    "    'payment_stress': {\n",
    "        'variables': ['LATE_PAYMENT_STRESS', 'SEVERE_LATE_STRESS', 'HIGH_PAYMENT_BURDEN'],\n",
    "        'direction': 'negative',  # Higher values = lower stability\n",
    "        'weight': 0.4\n",
    "    },\n",
    "    'debt_burden': {\n",
    "        'variables': ['DEBT_BURDEN_CONTINUOUS', 'LEVERAGE_CONTINUOUS', 'PAYMENT_STRESS_CONTINUOUS'],\n",
    "        'direction': 'negative',\n",
    "        'weight': 0.3\n",
    "    },\n",
    "    'financial_resilience': {\n",
    "        'variables': ['LOG_NETWORTH', 'LIQUID_ASSETS_IND', 'SAVING_BEHAVIOR'],\n",
    "        'direction': 'positive',  # Higher values = higher stability\n",
    "        'weight': 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create FSI components\n",
    "fsi_scores = {}\n",
    "available_components = []\n",
    "\n",
    "for component, config in fsi_components.items():\n",
    "    available_vars = [var for var in config['variables'] if var in df.columns]\n",
    "    \n",
    "    if len(available_vars) >= 2:\n",
    "        available_components.append(component)\n",
    "        \n",
    "        # Standardize variables\n",
    "        standardized_vars = []\n",
    "        for var in available_vars:\n",
    "            if config['direction'] == 'negative':\n",
    "                # Reverse for negative components (higher = worse)\n",
    "                standardized = -(df[var] - df[var].mean()) / df[var].std()\n",
    "            else:\n",
    "                # Normal standardization for positive components\n",
    "                standardized = (df[var] - df[var].mean()) / df[var].std()\n",
    "            standardized_vars.append(standardized)\n",
    "        \n",
    "        # Create component score (weighted average)\n",
    "        if len(standardized_vars) > 0:\n",
    "            component_score = np.mean(standardized_vars, axis=0)\n",
    "            fsi_scores[component] = component_score\n",
    "            df[f'FSI_{component.upper()}'] = component_score\n",
    "            \n",
    "            print(f\"    Created FSI_{component.upper()}: {len(available_vars)} variables\")\n",
    "            print(f\"      Variables: {available_vars}\")\n",
    "            print(f\"      Mean: {component_score.mean():.3f}, Std: {component_score.std():.3f}\")\n",
    "\n",
    "# Create overall FSI (weighted average of components)\n",
    "if len(fsi_scores) >= 2:\n",
    "    # Calculate weighted overall FSI\n",
    "    overall_fsi = 0\n",
    "    total_weight = 0\n",
    "    \n",
    "    for component, score in fsi_scores.items():\n",
    "        weight = fsi_components[component]['weight']\n",
    "        overall_fsi += score * weight\n",
    "        total_weight += weight\n",
    "    \n",
    "    # Normalize by total weight\n",
    "    overall_fsi = overall_fsi / total_weight\n",
    "    \n",
    "    df['FINANCIAL_STABILITY_INDEX'] = overall_fsi\n",
    "    \n",
    "    print(f\"\\n    Created FINANCIAL_STABILITY_INDEX: Overall FSI\")\n",
    "    print(f\"      Components: {list(fsi_scores.keys())}\")\n",
    "    print(f\"      Mean: {overall_fsi.mean():.3f}, Std: {overall_fsi.std():.3f}\")\n",
    "    print(f\"      Range: [{overall_fsi.min():.3f}, {overall_fsi.max():.3f}]\")\n",
    "    \n",
    "    # Create FSI categories for analysis\n",
    "    fsi_q33 = overall_fsi.quantile(0.33)\n",
    "    fsi_q67 = overall_fsi.quantile(0.67)\n",
    "    \n",
    "    df['FSI_CATEGORY'] = pd.cut(\n",
    "        overall_fsi,\n",
    "        bins=[-np.inf, fsi_q33, fsi_q67, np.inf],\n",
    "        labels=['Low_Stability', 'Medium_Stability', 'High_Stability']\n",
    "    )\n",
    "    \n",
    "    print(f\"      FSI Categories: {dict(df['FSI_CATEGORY'].value_counts())}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Insufficient components for comprehensive FSI\")\n",
    "\n",
    "print(f\"\\n Financial Stability Index Development Complete:\")\n",
    "print(f\"   Components created: {len(fsi_scores)}\")\n",
    "print(f\"   Overall FSI: {'' if 'FINANCIAL_STABILITY_INDEX' in df.columns else '‚ùå'}\")\n",
    "print(f\"   FSI Categories: {'' if 'FSI_CATEGORY' in df.columns else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Validate Financial Stability Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Financial Stability Index\n",
    "if 'FINANCIAL_STABILITY_INDEX' in df.columns:\n",
    "    print(\" Validating Financial Stability Index...\")\n",
    "    \n",
    "    # Correlation with target variables\n",
    "    fsi_correlations = {}\n",
    "    all_target_vars = (payment_stress_vars + debt_burden_vars + \n",
    "                        financial_position_vars + financial_knowledge_vars)\n",
    "    \n",
    "    for target_var in all_target_vars:\n",
    "        if target_var in df.columns:\n",
    "            correlation = df['FINANCIAL_STABILITY_INDEX'].corr(df[target_var])\n",
    "            fsi_correlations[target_var] = correlation\n",
    "    \n",
    "    # Create correlation DataFrame\n",
    "    fsi_corr_df = pd.DataFrame(list(fsi_correlations.items()), \n",
    "                                columns=['Variable', 'Correlation_with_FSI'])\n",
    "    fsi_corr_df = fsi_corr_df.sort_values('Correlation_with_FSI', key=abs, ascending=False)\n",
    "    \n",
    "    print(\"\\n FSI Correlations with Target Variables:\")\n",
    "    display(fsi_corr_df.head(10))\n",
    "    \n",
    "    # FSI by demographic groups\n",
    "    print(\"\\n FSI by Key Demographics:\")\n",
    "    \n",
    "    # By education\n",
    "    if 'EDCL' in df.columns:\n",
    "        fsi_by_education = df.groupby('EDCL')['FINANCIAL_STABILITY_INDEX'].agg(['mean', 'count', 'std'])\n",
    "        print(\"\\n   FSI by Education Level:\")\n",
    "        display(fsi_by_education.round(3))\n",
    "    \n",
    "    # By wealth quintile\n",
    "    if 'WEALTH_QUINTILE' in df.columns:\n",
    "        fsi_by_wealth = df.groupby('WEALTH_QUINTILE')['FINANCIAL_STABILITY_INDEX'].agg(['mean', 'count', 'std'])\n",
    "        print(\"\\n   FSI by Wealth Quintile:\")\n",
    "        display(fsi_by_wealth.round(3))\n",
    "    \n",
    "    # By income quintile\n",
    "    if 'INCOME_QUINTILE' in df.columns:\n",
    "        fsi_by_income = df.groupby('INCOME_QUINTILE')['FINANCIAL_STABILITY_INDEX'].agg(['mean', 'count', 'std'])\n",
    "        print(\"\\n   FSI by Income Quintile:\")\n",
    "        display(fsi_by_income.round(3))\n",
    "    \n",
    "    # Save FSI validation results\n",
    "    fsi_corr_df.to_csv(STUDIO4_OUTPUT / \"tables\" / \"fsi_correlations.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\n FSI validation results saved\")\n",
    "    print(f\"\\n FSI Validation Summary:\")\n",
    "    print(f\"   Strongest correlation: {fsi_corr_df.iloc[0]['Variable']} ({fsi_corr_df.iloc[0]['Correlation_with_FSI']:.3f})\")\n",
    "    print(f\"   FSI shows expected relationships with financial stability indicators\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå FSI not available for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Validation and Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Final Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data quality assessment for Studio 4\n",
    "print(\" Performing final Studio 4 data quality assessment...\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n Studio 4 Dataset Summary:\")\n",
    "print(f\"   Total households: {len(df):,}\")\n",
    "print(f\"   Total variables: {len(df.columns)}\")\n",
    "print(f\"   Missing values: {df.isna().sum().sum():,}\")\n",
    "print(f\"   Missing percentage: {(df.isna().sum().sum() / (len(df) * len(df.columns))) * 100:.2f}%\")\n",
    "\n",
    "# Variable category summary\n",
    "all_created_vars = {\n",
    "    'Target Variables': payment_stress_vars + debt_burden_vars + financial_position_vars + financial_knowledge_vars,\n",
    "    'Predictor Variables': education_vars + demographic_vars + wealth_background_vars + income_control_vars,\n",
    "    'Interaction Variables': interaction_vars + race_interaction_vars + income_interaction_vars,\n",
    "    'FSI Variables': [var for var in df.columns if 'FSI' in var.upper()]\n",
    "}\n",
    "\n",
    "print(f\"\\n Studio 4 Variable Summary:\")\n",
    "for category, vars_list in all_created_vars.items():\n",
    "    available_vars = [var for var in vars_list if var in df.columns]\n",
    "    print(f\"   {category}: {len(available_vars)} variables\")\n",
    "\n",
    "# Key variable availability check\n",
    "critical_research_vars = {\n",
    "    'Main Predictor': 'EDCL',\n",
    "    'Key Moderator': 'WEALTH_QUINTILE',\n",
    "    'Analysis Framework': 'INCOME_QUINTILE',\n",
    "    'Primary Target': 'COMPOSITE_PAYMENT_STRESS',\n",
    "    'Alternative Target': 'FINANCIAL_STABILITY_INDEX',\n",
    "    'Survey Weights': 'WGT'\n",
    "}\n",
    "\n",
    "print(f\"\\n Critical Research Variables Status:\")\n",
    "all_critical_available = True\n",
    "for purpose, var in critical_research_vars.items():\n",
    "    status = \"\" if var in df.columns else \"‚ùå\"\n",
    "    print(f\"   {purpose}: {status} {var}\")\n",
    "    if var not in df.columns:\n",
    "        all_critical_available = False\n",
    "\n",
    "if all_critical_available:\n",
    "    print(f\"\\n ALL CRITICAL RESEARCH VARIABLES AVAILABLE!\")\n",
    "else:\n",
    "    print(f\"\\n Some critical variables missing - review required\")\n",
    "\n",
    "# Sample size for within-income-quintile analysis\n",
    "if 'INCOME_QUINTILE' in df.columns:\n",
    "    quintile_sizes = df['INCOME_QUINTILE'].value_counts().sort_index()\n",
    "    print(f\"\\nüìà Sample Sizes by Income Quintile:\")\n",
    "    for quintile, size in quintile_sizes.items():\n",
    "        if quintile > 0:  # Exclude quintile 0 (non-positive income)\n",
    "            print(f\"   Quintile {quintile}: {size:,} households\")\n",
    "    \n",
    "    min_quintile_size = quintile_sizes[quintile_sizes.index > 0].min() if len(quintile_sizes[quintile_sizes.index > 0]) > 0 else 0\n",
    "    if min_quintile_size >= 1000:\n",
    "        print(f\"    Minimum quintile size ({min_quintile_size:,}) sufficient for analysis\")\n",
    "    else:\n",
    "        print(f\"    Minimum quintile size ({min_quintile_size:,}) may limit analysis\")\n",
    "\n",
    "print(f\"\\n Studio 4 Data Quality Assessment: {'READY' if all_critical_available else 'NEEDS REVIEW'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Save Studio 4 Dataset and Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Studio 4 research dataset\n",
    "print(\" Saving Studio 4 research dataset...\")\n",
    "\n",
    "# Create final research dataset\n",
    "studio4_research_path = STUDIO4_OUTPUT / \"tables\" / \"studio4_research_dataset.csv\"\n",
    "df.to_csv(studio4_research_path, index=False)\n",
    "print(f\"    Studio 4 research dataset saved: {studio4_research_path}\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "\n",
    "# Save variable documentation\n",
    "variable_documentation = {\n",
    "    'target_variables': {\n",
    "        'payment_stress': payment_stress_vars,\n",
    "        'debt_burden': debt_burden_vars,\n",
    "        'financial_position': financial_position_vars,\n",
    "        'financial_knowledge': financial_knowledge_vars\n",
    "    },\n",
    "    'predictor_variables': {\n",
    "        'education': education_vars,\n",
    "        'demographics': demographic_vars,\n",
    "        'wealth_background': wealth_background_vars,\n",
    "        'income_controls': income_control_vars\n",
    "    },\n",
    "    'interaction_variables': {\n",
    "        'education_wealth': interaction_vars,\n",
    "        'education_race': race_interaction_vars,\n",
    "        'education_income': income_interaction_vars\n",
    "    },\n",
    "    'fsi_variables': [var for var in df.columns if 'FSI' in var.upper()],\n",
    "    'critical_research_vars': critical_research_vars\n",
    "}\n",
    "\n",
    "with open(STUDIO4_OUTPUT / \"tables\" / \"studio4_variable_documentation.json\", 'w') as f:\n",
    "    json.dump(variable_documentation, f, indent=2)\n",
    "print(f\"    Variable documentation saved\")\n",
    "\n",
    "# Save data quality assessment\n",
    "quality_assessment = {\n",
    "    'dataset_shape': df.shape,\n",
    "    'missing_values': int(df.isna().sum().sum()),\n",
    "    'missing_percentage': float((df.isna().sum().sum() / (len(df) * len(df.columns))) * 100),\n",
    "    'critical_variables_available': all_critical_available,\n",
    "    'variable_counts': {category: len(vars_list) for category, vars_list in all_created_vars.items()},\n",
    "    'creation_timestamp': pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(STUDIO4_OUTPUT / \"tables\" / \"studio4_quality_assessment.json\", 'w') as f:\n",
    "    json.dump(quality_assessment, f, indent=2)\n",
    "print(f\"    Quality assessment saved\")\n",
    "\n",
    "print(f\"\\n Studio 4 research setup complete!\")\n",
    "print(f\"\\n Summary:\")\n",
    "print(f\"   Dataset: {df.shape[0]:,} households √ó {df.shape[1]} variables\")\n",
    "print(f\"   Target variables: {len(payment_stress_vars + debt_burden_vars + financial_position_vars + financial_knowledge_vars)}\")\n",
    "print(f\"   Predictor variables: {len(education_vars + demographic_vars + wealth_background_vars + income_control_vars)}\")\n",
    "print(f\"   Interaction variables: {len(interaction_vars + race_interaction_vars + income_interaction_vars)}\")\n",
    "print(f\"   FSI developed: {'' if 'FINANCIAL_STABILITY_INDEX' in df.columns else '‚ùå'}\")\n",
    "print(f\"   Research ready: {'' if all_critical_available else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\nüìÅ Files saved to {STUDIO4_OUTPUT}:\")\n",
    "print(f\"   üìÑ studio4_research_dataset.csv\")\n",
    "print(f\"   üìÑ studio4_variable_documentation.json\")\n",
    "print(f\"   üìÑ studio4_quality_assessment.json\")\n",
    "print(f\"   üìÑ fsi_correlations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Studio 4 Notebook 00 Completion Status\n",
    "\n",
    "**Status**:  COMPLETE\n",
    "\n",
    "**Accomplished**:\n",
    "-  Environment setup with Studio 4 specific directories\n",
    "-  Loaded MVP-prepared dataset with all required variables\n",
    "-  Comprehensive research variable framework defined\n",
    "-  **Target Variables Created**:\n",
    "  - Payment stress indicators (late payments, high payment burden)\n",
    "  - Debt burden measures (debt-to-income ratios, leverage)\n",
    "  - Financial position indicators (net worth, liquid assets, saving behavior)\n",
    "  - Financial knowledge measures\n",
    "-  **Predictor Variables Prepared**:\n",
    "  - Education variables (main predictor with dummies)\n",
    "  - Demographic controls (race, gender, age, marital status, children)\n",
    "  - Wealth background variables (quintiles, net worth, asset ownership)\n",
    "  - Income controls (quintiles, continuous income, source composition)\n",
    "-  **Interaction Terms Created**:\n",
    "  - Education √ó Wealth interaction (key moderation effect)\n",
    "  - Education √ó Race interaction (demographic moderation)\n",
    "  - Education √ó Income interaction (income-level moderation)\n",
    "-  **Financial Stability Index Developed**:\n",
    "  - Payment stress component (40% weight)\n",
    "  - Debt burden component (30% weight)\n",
    "  - Financial resilience component (30% weight)\n",
    "  - Overall FSI with categorical classifications\n",
    "-  **Data Validation and Quality Checks**:\n",
    "  - Critical research variables availability confirmed\n",
    "  - Sample sizes for within-income-quintile analysis validated\n",
    "  - FSI correlations with target variables verified\n",
    "-  **Documentation and Export**:\n",
    "  - Complete variable documentation\n",
    "  - Data quality assessment\n",
    "  - Research dataset ready for analysis\n",
    "\n",
    "**Key Research Variables Status**:\n",
    "-  Main Predictor: EDCL (education class)\n",
    "-  Key Moderator: WEALTH_QUINTILE (wealth background)\n",
    "-  Analysis Framework: INCOME_QUINTILE (within-quintile analysis)\n",
    "-  Primary Target: COMPOSITE_PAYMENT_STRESS\n",
    "-  Alternative Target: FINANCIAL_STABILITY_INDEX\n",
    "-  Survey Weights: WGT (for representative analysis)\n",
    "\n",
    "**Sample Sizes for Analysis**:\n",
    "- Income quintiles: Sufficient for within-quintile analysis\n",
    "- Education √ó Wealth interactions: Multiple combinations available\n",
    "- Demographic subgroups: Adequate sample sizes for most groups\n",
    "\n",
    "**Ready for Next Step**: Studio 4 Notebook 01 - Descriptive Analysis\n",
    "\n",
    "** Studio 4 Research Setup: COMPLETE AND READY FOR ANALYSIS**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "variation": "python"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}